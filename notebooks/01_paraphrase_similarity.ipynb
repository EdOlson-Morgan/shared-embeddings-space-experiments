{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Paraphrase Similarity Experiment\n",
                "\n",
                "This notebook explores how Voyage AI embeddings capture semantic similarity between paraphrases.\n",
                "\n",
                "**Hypothesis**: Texts that are paraphrases of each other should have high cosine similarity in the embedding space, while unrelated texts should have lower similarity scores."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup\n",
                "\n",
                "First, let's load our dependencies and configure the environment."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import sys\n",
                "import os\n",
                "from pathlib import Path\n",
                "\n",
                "# Get the project root directory (parent of notebooks/)\n",
                "NOTEBOOK_DIR = Path(os.path.dirname(os.path.abspath('__file__'))).resolve()\n",
                "# If we're in notebooks/, go up one level; otherwise assume we're at project root\n",
                "if NOTEBOOK_DIR.name == 'notebooks':\n",
                "    PROJECT_ROOT = NOTEBOOK_DIR.parent\n",
                "else:\n",
                "    PROJECT_ROOT = NOTEBOOK_DIR\n",
                "\n",
                "# Add src to path for local imports\n",
                "sys.path.insert(0, str(PROJECT_ROOT / 'src'))\n",
                "\n",
                "print(f\"Project root: {PROJECT_ROOT}\")\n",
                "print(f\"Source path: {PROJECT_ROOT / 'src'}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "from embeddings_space.embeddings import EmbeddingsClient\n",
                "from embeddings_space.metrics import cosine_similarity, pairwise_similarities\n",
                "\n",
                "# Set up plotting style\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "sns.set_palette('husl')"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Load Paraphrase Data\n",
                "\n",
                "We have a dataset with groups of paraphrases (semantically equivalent texts) and some unrelated texts for comparison."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load the paraphrase dataset\n",
                "with open(PROJECT_ROOT / 'data' / 'paraphrases.json', 'r') as f:\n",
                "    data = json.load(f)\n",
                "\n",
                "print(f\"Loaded {len(data['paraphrase_groups'])} paraphrase groups\")\n",
                "print(f\"Loaded {len(data['unrelated_texts'])} unrelated texts\")\n",
                "\n",
                "# Preview the data\n",
                "for group in data['paraphrase_groups']:\n",
                "    print(f\"\\nüìù {group['topic']} ({len(group['texts'])} variants)\")\n",
                "    print(f\"   Example: {group['texts'][0][:80]}...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Generate Embeddings\n",
                "\n",
                "Connect to Voyage AI and generate embeddings for all texts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Initialize the embeddings client\n",
                "# Make sure VOYAGE_API_KEY is set in your .env file\n",
                "client = EmbeddingsClient(model=\"voyage-4-large\")\n",
                "\n",
                "print(f\"Using model: {client.model}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect all texts and their metadata\n",
                "all_texts = []\n",
                "text_labels = []\n",
                "group_ids = []\n",
                "\n",
                "# Add paraphrase groups\n",
                "for group in data['paraphrase_groups']:\n",
                "    for i, text in enumerate(group['texts']):\n",
                "        all_texts.append(text)\n",
                "        text_labels.append(f\"{group['id']}_{i+1}\")\n",
                "        group_ids.append(group['id'])\n",
                "\n",
                "# Add unrelated texts\n",
                "for item in data['unrelated_texts']:\n",
                "    all_texts.append(item['text'])\n",
                "    text_labels.append(item['id'])\n",
                "    group_ids.append('unrelated')\n",
                "\n",
                "print(f\"Total texts to embed: {len(all_texts)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Generate embeddings for all texts\n",
                "embeddings = client.embed_texts(all_texts)\n",
                "\n",
                "print(f\"Embedding shape: {embeddings.shape}\")\n",
                "print(f\"Embedding dimension: {embeddings.shape[1]}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Analyze Similarity\n",
                "\n",
                "Compute pairwise cosine similarities and visualize the results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Compute pairwise cosine similarities\n",
                "similarity_matrix = pairwise_similarities(embeddings, metric=\"cosine\")\n",
                "\n",
                "# Create a DataFrame for easier analysis\n",
                "sim_df = pd.DataFrame(\n",
                "    similarity_matrix,\n",
                "    index=text_labels,\n",
                "    columns=text_labels\n",
                ")\n",
                "\n",
                "print(\"Similarity matrix shape:\", sim_df.shape)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create a heatmap visualization\n",
                "fig, ax = plt.subplots(figsize=(14, 12))\n",
                "\n",
                "sns.heatmap(\n",
                "    sim_df,\n",
                "    annot=True,\n",
                "    fmt='.2f',\n",
                "    cmap='RdYlGn',\n",
                "    center=0.5,\n",
                "    vmin=0,\n",
                "    vmax=1,\n",
                "    ax=ax,\n",
                "    annot_kws={'size': 8}\n",
                ")\n",
                "\n",
                "ax.set_title('Cosine Similarity Matrix: Paraphrases vs Unrelated Texts', fontsize=14)\n",
                "plt.xticks(rotation=45, ha='right')\n",
                "plt.yticks(rotation=0)\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Statistical Analysis\n",
                "\n",
                "Compare the similarity distributions between paraphrases and unrelated texts."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Collect similarity scores by relationship type\n",
                "within_group_similarities = []\n",
                "between_group_similarities = []\n",
                "\n",
                "n = len(all_texts)\n",
                "for i in range(n):\n",
                "    for j in range(i + 1, n):\n",
                "        sim = similarity_matrix[i, j]\n",
                "        if group_ids[i] == group_ids[j] and group_ids[i] != 'unrelated':\n",
                "            within_group_similarities.append(sim)\n",
                "        else:\n",
                "            between_group_similarities.append(sim)\n",
                "\n",
                "print(f\"Within-group pairs: {len(within_group_similarities)}\")\n",
                "print(f\"Between-group pairs: {len(between_group_similarities)}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Summary statistics\n",
                "print(\"=\" * 50)\n",
                "print(\"SIMILARITY STATISTICS\")\n",
                "print(\"=\" * 50)\n",
                "print(f\"\\nüìä Within-group (paraphrases):\")\n",
                "print(f\"   Mean: {np.mean(within_group_similarities):.4f}\")\n",
                "print(f\"   Std:  {np.std(within_group_similarities):.4f}\")\n",
                "print(f\"   Min:  {np.min(within_group_similarities):.4f}\")\n",
                "print(f\"   Max:  {np.max(within_group_similarities):.4f}\")\n",
                "\n",
                "print(f\"\\nüìä Between-group (different topics):\")\n",
                "print(f\"   Mean: {np.mean(between_group_similarities):.4f}\")\n",
                "print(f\"   Std:  {np.std(between_group_similarities):.4f}\")\n",
                "print(f\"   Min:  {np.min(between_group_similarities):.4f}\")\n",
                "print(f\"   Max:  {np.max(between_group_similarities):.4f}\")\n",
                "\n",
                "print(f\"\\nüéØ Separation gap: {np.mean(within_group_similarities) - np.mean(between_group_similarities):.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Distribution visualization\n",
                "fig, ax = plt.subplots(figsize=(10, 6))\n",
                "\n",
                "ax.hist(\n",
                "    within_group_similarities,\n",
                "    bins=20,\n",
                "    alpha=0.7,\n",
                "    label='Paraphrases (within group)',\n",
                "    color='#2ecc71'\n",
                ")\n",
                "ax.hist(\n",
                "    between_group_similarities,\n",
                "    bins=20,\n",
                "    alpha=0.7,\n",
                "    label='Different topics (between groups)',\n",
                "    color='#e74c3c'\n",
                ")\n",
                "\n",
                "ax.axvline(\n",
                "    np.mean(within_group_similarities),\n",
                "    color='#27ae60',\n",
                "    linestyle='--',\n",
                "    linewidth=2,\n",
                "    label=f'Paraphrase mean: {np.mean(within_group_similarities):.3f}'\n",
                ")\n",
                "ax.axvline(\n",
                "    np.mean(between_group_similarities),\n",
                "    color='#c0392b',\n",
                "    linestyle='--',\n",
                "    linewidth=2,\n",
                "    label=f'Different topic mean: {np.mean(between_group_similarities):.3f}'\n",
                ")\n",
                "\n",
                "ax.set_xlabel('Cosine Similarity', fontsize=12)\n",
                "ax.set_ylabel('Frequency', fontsize=12)\n",
                "ax.set_title('Distribution of Similarity Scores', fontsize=14)\n",
                "ax.legend(loc='upper left')\n",
                "ax.set_xlim(0, 1)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusions\n",
                "\n",
                "The results above should demonstrate:\n",
                "\n",
                "1. **Paraphrases cluster together**: Texts with the same semantic meaning but different wording have high cosine similarity\n",
                "2. **Unrelated texts are distant**: Texts on different topics have lower similarity scores\n",
                "3. **Clear separation**: There should be a measurable gap between within-group and between-group similarities\n",
                "\n",
                "This validates that Voyage embeddings effectively capture semantic similarity, making them useful for paraphrase detection, semantic search, and similar applications."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Next Steps\n",
                "\n",
                "Potential follow-up experiments:\n",
                "- Compare different Voyage models (voyage-4-large vs voyage-4-lite vs voyage-3.5)\n",
                "- Test cross-lingual paraphrases\n",
                "- Explore the shared embedding space with code examples (voyage-code-3)\n",
                "- Visualize embeddings using dimensionality reduction (UMAP, t-SNE)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}